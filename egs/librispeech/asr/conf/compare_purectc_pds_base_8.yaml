arch: s2t_ctc
encoder-type: pds

#encoder-attention-type: reduced
#pds-attn-ds-ratios: 4_2_1_1
#attention-reduced-method: pool
#attention-reduced-q: True

encoder-embed-dim: 240
pds-stages: 3
pds-layers: 5_5_5
pds-ratios: 2_2_2
pds-fusion: False
pds-fusion-method: all_conv2
pds-fusion-layers: 0_1_1_1 
pds-fusion-weight: 0.2_0.3_0.5
pds-embed-dims: 120_168_240
pds-ds-method: conv
pds-embed-norm: True
pds-position-embed: 1_1_1
pds-kernel-sizes: 5_5_5
pds-ffn-ratios: 4_4_4
pds-attn-heads: 4_4_4

optimizer: adam
clip-norm: 10.0
lr-scheduler: inverse_sqrt
warmup-init-lr: 1e-7
warmup-updates: 10000
weight-decay: 1e-6
lr: 0.002
adam_betas: (0.9,0.98)

criterion: ctc
ctc-weight: 1.0

dropout: 0.1
activation-fn: relu
encoder-layers: 15

macaron-style: True
use-cnn-module: True
cnn-module-kernel: 15
encoder-activation-fn: swish
encoder-attention-type: rel_pos

#load-pretrained-encoder-from:
